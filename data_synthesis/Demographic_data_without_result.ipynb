{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic Synthetic Data Generated for Campaign System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## for simplicity, we simply randomly select 1000 customers and use their recommendation result in subgroup_B qn 2\n",
    "product = pd.read_csv('../../data/predictions/BQ1.csv')\n",
    "product = product.sample(4000, random_state=3101)\n",
    "product = product.drop('Cluster', axis=1)\n",
    "def get_highest_probability_product(df):\n",
    "    \"\"\"\n",
    "    Function to find the highest probability product for each client.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame containing client IDs and product probabilities.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing 'CLIENTNUM' and the highest probability 'product' for each client.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame with the highest probability product for each client\n",
    "    result = pd.DataFrame({\n",
    "        'CLIENTNUM': df['CLIENTNUM'],\n",
    "        'product': df.drop(columns='CLIENTNUM').idxmax(axis=1)\n",
    "    })\n",
    "    return result\n",
    "product = get_highest_probability_product(product)\n",
    "df = product.reset_index(drop = True)\n",
    "## we generate a campaign dataset for a campaign happens a month\n",
    "product_to_campaign_type = {\n",
    "    'credit_cards': 'Consideration',\n",
    "    'savings_accounts': 'Consideration',\n",
    "    'investments': 'Conversion',\n",
    "    'personal_insurance': 'Conversion',\n",
    "    'commercial_insurance': 'Conversion',\n",
    "    'personal_loans': 'Conversion',\n",
    "    'commercial_loans': 'Conversion'\n",
    "}\n",
    "\n",
    "# Assign campaign IDs for each campaign type\n",
    "campaign_type_to_id = {\n",
    "    'Conversion': 'C1',\n",
    "    'Retention': 'C2',\n",
    "    'Consideration': 'C3'\n",
    "}\n",
    "\n",
    "# Create a campaign database DataFrame\n",
    "campaign_data = []\n",
    "response_weight = {'Conversion': [0.05, 0.10, 0.85],\n",
    "                  'Retention': [0.15, 0.20, 0.65],\n",
    "                  'Consideration': [0.10, 0.15, 0.75]}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    product = row['product']\n",
    "    clientnum = row['CLIENTNUM']\n",
    "    campaign_type = product_to_campaign_type[product]\n",
    "    campaign_id = campaign_type_to_id[campaign_type]\n",
    "    \n",
    "    # Different Campaign have different duration\n",
    "    if campaign_type in ['Conversion', 'Consideration']:\n",
    "        end_date = datetime.now() + timedelta(days=60)  \n",
    "    elif campaign_type == 'Consideration':\n",
    "        end_date = datetime.now() + timedelta(days=30)\n",
    "    else:\n",
    "        end_date = datetime.now() \n",
    "    \n",
    "\n",
    "    campaign_entry = {\n",
    "        'CLIENTNUM': clientnum,\n",
    "        'Campaign_ID': campaign_id,\n",
    "        'Campaign_Type': campaign_type,\n",
    "        'Product': product,\n",
    "        'Start_Date': datetime.now(),\n",
    "        'End_Date': end_date,\n",
    "        'ResponseStatus': random.choices(['Success', 'Rejected', 'Unknown'], weights=response_weight[campaign_type])[0],\n",
    "        'NumberOfImpressions': random.randint(100, 1000),\n",
    "        'NumberOfClicks': random.randint(10, 100)\n",
    "    }\n",
    "    campaign_data.append(campaign_entry)\n",
    "\n",
    "campaign_df = pd.DataFrame(campaign_data)\n",
    "def create_campaign_log(campaign_database):\n",
    "    \"\"\"\n",
    "    Creates a campaign log by grouping the campaign database by CampaignID and calculating\n",
    "    the total number of impressions, clicks, and conversion rate for each campaign.\n",
    "    \n",
    "    Parameters:\n",
    "    campaign_database (DataFrame): The original campaign database.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: A new campaign log DataFrame with aggregated metrics and default settings.\n",
    "    \"\"\"\n",
    "    # Group by CampaignID and aggregate the number of impressions, clicks, and responses\n",
    "    campaign_log = campaign_database.groupby('Campaign_ID').agg(\n",
    "        TotalImpressions=('NumberOfImpressions', 'sum'),\n",
    "        TotalClicks=('NumberOfClicks', 'sum'),\n",
    "        TotalResponses=('ResponseStatus', lambda x: (x == 'Success').sum())\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate conversion rate and click-through rate (CTR)\n",
    "    campaign_log['ConversionRate'] = campaign_log['TotalResponses'] / campaign_log['TotalImpressions']\n",
    "    campaign_log['ClickThroughRate'] = campaign_log['TotalClicks'] / campaign_log['TotalImpressions']\n",
    "\n",
    "    # Fill NaN values with 0 for rates where TotalImpressions might be 0\n",
    "    campaign_log['ConversionRate'] = campaign_log['ConversionRate'].fillna(0)\n",
    "    campaign_log['ClickThroughRate'] = campaign_log['ClickThroughRate'].fillna(0)\n",
    "\n",
    "    # Add default channel, frequency, and timing\n",
    "    nrows = len(campaign_log)\n",
    "    campaign_log['ChosenChannel'] = ['Email'] * nrows\n",
    "    campaign_log['ChosenFrequency'] = [1] * nrows\n",
    "    campaign_log['ChosenTiming'] = [6] * nrows\n",
    "    \n",
    "    return campaign_log\n",
    "\n",
    "campaign_log = create_campaign_log(campaign_df)\n",
    "campaign_log\n",
    "# Function to generate synthetic campaign data\n",
    "def generate_synthetic_campaign_data(num_rows, campaign_type, campaign_id):\n",
    "    data = []\n",
    "    for _ in range(num_rows):\n",
    "        entry = {\n",
    "            'CLIENTNUM': random.randint(100000000, 999999999),  # Random 9-digit client number\n",
    "            'Campaign_ID': campaign_id,\n",
    "            'Campaign_Type': campaign_type,\n",
    "            'Product': random.choice(['credit_cards', 'savings_accounts', 'personal_loans']),  # Random product example\n",
    "            'Start_Date': datetime.now(),\n",
    "            'End_Date': datetime.now() + timedelta(days=90) if campaign_type == 'Consideration' else datetime.now() + timedelta(days=30),\n",
    "            'ResponseStatus': random.choices(['Success', 'Rejected', 'Unknown'], weights=response_weight[campaign_type])[0],\n",
    "            'NumberOfImpressions': random.randint(100, 1000),\n",
    "            'NumberOfClicks': random.randint(10, 100)\n",
    "        }\n",
    "        data.append(entry)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "retention_df = generate_synthetic_campaign_data(2000, 'Retention', 'C2')\n",
    "consideration_df = generate_synthetic_campaign_data(4000, 'Consideration', 'C3')\n",
    "\n",
    "# Combine the dataframes if needed\n",
    "combined_df = pd.concat([retention_df, consideration_df], ignore_index=True)\n",
    "campaign_df = pd.concat([campaign_df, combined_df], ignore_index=True)\n",
    "campaign_log = create_campaign_log(campaign_df)\n",
    "campaign_log\n",
    "demographic = pd.read_csv(\"../../data/processed/banking_behaviour_preference.csv\")\n",
    "demographic = demographic.sample(10000, random_state=3101)\n",
    "### it takes too long to generate transaction data for calculating rfm score, we will simply generate it randomly\n",
    "# Calculate RFM metrics for synthetic data\n",
    "demographic['Recency'] = np.random.randint(1, 365, 10000)  # Days since last interaction\n",
    "demographic['Recency'] = 1 - (demographic['Recency'] / demographic['Recency'].max())  # Normalize and invert\n",
    "demographic['Frequency'] = demographic['Total_Trans_Count'] / demographic['Total_Trans_Count'].max()  # Normalize\n",
    "demographic['Monetary'] = demographic['Total_Trans_Amt'] / demographic['Total_Trans_Amt'].max()  # Normalize\n",
    "# Calculate RFM engagement score\n",
    "w_R, w_F, w_M = 0.4, 0.3, 0.3\n",
    "demographic['engagement_score'] = w_R * demographic['Recency'] + w_F * demographic['Frequency'] + w_M * demographic['Monetary']\n",
    "c1_df = pd.concat([campaign_log[campaign_log['Campaign_ID'] == 'C1']] * 4000, ignore_index=True)\n",
    "c2_df = pd.concat([campaign_log[campaign_log['Campaign_ID'] == 'C2']] * 2000, ignore_index=True)\n",
    "c3_df = pd.concat([campaign_log[campaign_log['Campaign_ID'] == 'C3']] * 4000, ignore_index=True)\n",
    "\n",
    "# Combine the expanded DataFrames\n",
    "campaign_log = pd.concat([c1_df, c2_df, c3_df], ignore_index=True)\n",
    "demographic['ClickThroughRate'] = campaign_log['ClickThroughRate'].values\n",
    "demographic['ConversionRate'] = campaign_log['ConversionRate'].values\n",
    "demographic['ChosenTiming'] = campaign_log['ChosenTiming'].values\n",
    "demographic['ChosenFrequency'] = campaign_log['ChosenFrequency'].values\n",
    "demographic['ChosenChannel'] = campaign_log['ChosenChannel'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic.to_csv(\"../../data/processed/demographic.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
