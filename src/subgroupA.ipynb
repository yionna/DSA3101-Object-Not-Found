{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv(\"../data/BankChurners.csv\")\n",
    "balance_df = pd.read_csv(\"../data/botswana_bank_customer_churn.csv\")\n",
    "technical_df = pd.read_csv(\"../data/User churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing irrelevent columns\n",
    "original = original.drop(original.columns[[-1, -2]], axis=1)\n",
    "original = original.drop(columns=['Avg_Open_To_Buy','Total_Amt_Chng_Q4_Q1','Contacts_Count_12_mon','Total_Ct_Chng_Q4_Q1'])\n",
    "\n",
    "# renaming the datasets\n",
    "original = original.rename(columns={'Months_on_book' : 'Month_with_bank',\n",
    "                                    'Total_Relationship_Count' : 'No_of_product',\n",
    "                                    'Total_Trans_Ct' : 'Total_Trans_Count'})\n",
    "\n",
    "# removing Na from the dataset\n",
    "original_Unknown = original[original.isin(['Unknown']).any(axis=1)] # someone handle the unknown please\n",
    "original = original[~original.isin(['Unknown']).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will remove the k,$ and + sign in the income category column\n",
    "def clean_col(x):\n",
    "        if 'K' in x:\n",
    "            return x.replace('K','').replace('$','')\n",
    "        elif '+' in x:\n",
    "            return x.replace('+','')\n",
    "        elif x =='Less than 40':\n",
    "            return x.split()[2]\n",
    "        return x\n",
    "    \n",
    "original['Income_Category']=original['Income_Category'].apply(clean_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting object into category\n",
    "categorical_features = ['Attrition_Flag','Gender','Education_Level','Marital_Status','Income_Category','Card_Category']\n",
    "for category in categorical_features:\n",
    "    original[category] = original[category].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Synthetic data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Balance dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in  `Credit Score`,`Outstanding Loans`, `Balance` from balance dataset. The final dataframe is stored as `final_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting from the original data\n",
    "required_features = [\"CLIENTNUM\",\"Customer_Age\",\"Gender\",\"Income_Category\",\"No_of_product\"]\n",
    "subset_original = original.loc[:,required_features]\n",
    "\n",
    "# subsetting from the income data\n",
    "required_features2 = ['Date of Birth','Gender','Income','NumOfProducts','Credit Score','Outstanding Loans', 'Balance']\n",
    "subset_balance = balance_df.loc[:,required_features2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing date of birth to date time and them convert it to age\n",
    "subset_balance['Date of Birth'] = pd.to_datetime(subset_balance['Date of Birth'])\n",
    "reference_date = pd.Timestamp('2024-01-01')\n",
    "subset_balance['Date of Birth'] = reference_date.year - subset_balance['Date of Birth'].dt.year\n",
    "\n",
    "# Changing income into income category\n",
    "bins = [0, 40000, 60000, 80000, 120000, float('inf')]\n",
    "labels = ['Less than 40', '40 - 60', '60 - 80', '80 - 120', '120 +']\n",
    "subset_balance['Income'] = pd.cut(subset_balance['Income'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Recoding Male to M...\n",
    "subset_balance['Gender'] = subset_balance['Gender'].replace({'Male':'M','Female':'F'})\n",
    "\n",
    "# Renaming the balance_subset dataframe\n",
    "subset_balance = subset_balance.rename(columns = {'Date of Birth' : \"Customer_Age\", \n",
    "                                        'Income' : \"Income_Category\", 'NumOfProducts' : \"No_of_product\"})\n",
    "\n",
    "# Converting object to category\n",
    "subset_balance['Gender'] = subset_balance['Gender'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling \n",
    "scaler = MinMaxScaler()\n",
    "subset_balance[['Customer_Age','No_of_product']] = scaler.fit_transform(subset_balance[['Customer_Age','No_of_product']])\n",
    "subset_original[['Customer_Age','No_of_product']] = scaler.fit_transform(subset_original[['Customer_Age','No_of_product']])\n",
    "\n",
    "# Encode the categorical variables\n",
    "le_gender = LabelEncoder()\n",
    "subset_balance['Gender_Encoded'] = le_gender.fit_transform(subset_balance['Gender'])\n",
    "subset_original['Gender_Encoded'] = le_gender.fit_transform(subset_original['Gender'])\n",
    "\n",
    "le_income = LabelEncoder()\n",
    "subset_balance['Income_Category_Encoded'] = le_income.fit_transform(subset_balance['Income_Category'])\n",
    "subset_original['Income_Category_Encoded'] = le_income.fit_transform(subset_original['Income_Category'])\n",
    "\n",
    "# Extract relevant features for clustering\n",
    "features_balance = subset_balance[['Customer_Age', 'No_of_product', 'Gender_Encoded', 'Income_Category_Encoded']]\n",
    "features_original = subset_original[['Customer_Age', 'No_of_product', 'Gender_Encoded', 'Income_Category_Encoded']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KMeans clustering on balance data and find optimal clusters\n",
    "cluster_range = range(2, 7)  # Define the range of cluster numbers to test\n",
    "inertia_values = []  # Inertia will help determine the optimal cluster number\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(features_balance)\n",
    "    inertia_values.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow method to determine the best cluster count\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(cluster_range, inertia_values, marker='o', linestyle='--', color='b')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the final KMeans model with the selected number of clusters\n",
    "optimal_k = 5  # Choosen based on the elbow plot\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=3101)\n",
    "kmeans_final.fit(features_balance)\n",
    "subset_balance['Cluster_Labels'] = kmeans_final.labels_\n",
    "\n",
    "#Predict cluster labels for the original subset using the same KMeans model\n",
    "subset_original['Cluster_Labels'] = kmeans_final.predict(features_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of target variables\n",
    "target_columns = ['Credit Score','Outstanding Loans', 'Balance']\n",
    "\n",
    "# Dictionary to hold fitted parameters (mean, std) for each cluster and each target variable\n",
    "cluster_params = {}\n",
    "\n",
    "for target in target_columns:\n",
    "    cluster_params[target] = {}\n",
    "    # Group by clusters\n",
    "    for cluster in subset_balance['Cluster_Labels'].unique():\n",
    "        cluster_data = subset_balance[subset_balance['Cluster_Labels'] == cluster][target]\n",
    "        # Fit a normal distribution to the data in the cluster\n",
    "        mean, std = norm.fit(cluster_data)\n",
    "        cluster_params[target][cluster] = (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to draw samples based on the cluster label using CLIENTNUM\n",
    "def generate_synthetic_data_with_clientnum(base_data, cluster_params, target):\n",
    "    # Initialize a dictionary for storing CLIENTNUM and synthetic values\n",
    "    synthetic_values = {}\n",
    "    \n",
    "    # Iterate over each record in the base data\n",
    "    for idx, row in base_data.iterrows():\n",
    "        clientnum = row['CLIENTNUM']  # Fetch the unique identifier\n",
    "        cluster_label = row['Cluster_Labels']  # Assuming cluster labels are already assigned to base data\n",
    "        mean, std = cluster_params[target][cluster_label]\n",
    "        \n",
    "        # Draw a sample from the normal distribution\n",
    "        synthetic_value = norm.rvs(loc=mean, scale=std)\n",
    "        \n",
    "        # Store the synthetic value with CLIENTNUM as the key\n",
    "        synthetic_values[clientnum] = synthetic_value\n",
    "    \n",
    "    return synthetic_values\n",
    "\n",
    "# Generate synthetic data for each target variable in the original subset\n",
    "for target in target_columns:\n",
    "    synthetic_data = generate_synthetic_data_with_clientnum(subset_original, cluster_params, target)\n",
    "    \n",
    "    # Add the synthetic data to the original subset using CLIENTNUM as the identifier\n",
    "    subset_original[f'{target}'] = subset_original['CLIENTNUM'].map(synthetic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Technical dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section aims to generate synthetic data for digital engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_features_original = ['CLIENTNUM', 'Gender', 'Customer_Age', 'Marital_Status', 'Dependent_count', 'Attrition_Flag']\n",
    "subset_original2 = original.loc[:,required_features_original]\n",
    "\n",
    "required_features_tech = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'Churn',\n",
    "                          'PhoneService', 'InternetService', 'TechSupport', 'PaperlessBilling', 'PaymentMethod']\n",
    "subset_technical = technical_df.loc[:,required_features_tech]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_original2['SeniorCitizen'] = (subset_original2['Customer_Age'] > 60).astype(int)\n",
    "subset_original2['Dependents'] = subset_original2['Dependent_count'].apply(lambda x: 'Yes' if x > 0 else 'No')\n",
    "\n",
    "subset_original2.drop(['Customer_Age', 'Dependent_count'], axis = 1, inplace = True)\n",
    "\n",
    "subset_technical['gender'] = subset_technical['gender'].replace({'Male':'M','Female':'F'})\n",
    "subset_technical['Churn'] = subset_technical['Churn'].replace({'Attrited Customer':'Yes','Existing Customer':'No'})\n",
    "subset_technical['Partner'] = subset_technical['Partner'].replace({'Married':'Yes','Single':'No'})\n",
    "\n",
    "subset_technical = subset_technical.rename(columns = {'gender' : \"Gender\", 'Churn' : \"Attrition_Flag\", 'Partner' : \"Marital_Status\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# List of categorical features\n",
    "modified_features_tech = ['Gender', 'SeniorCitizen', 'Marital_Status', 'Dependents', 'Attrition_Flag', \n",
    "                          'PhoneService', 'InternetService', 'TechSupport', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "# Initialize dictionaries to store encodings\n",
    "encodings_technical = {}\n",
    "encodings_original2 = {}\n",
    "\n",
    "# Encoding for subset_technical\n",
    "for feature in modified_features_tech:\n",
    "    # Convert to category type\n",
    "    subset_technical[feature] = subset_technical[feature].astype('category')\n",
    "    if feature in subset_original2:\n",
    "        subset_original2[feature] = subset_original2[feature].astype('category')\n",
    "\n",
    "# Apply LabelEncoder and show mappings\n",
    "for feature in modified_features_tech:\n",
    "    le_technical = LabelEncoder()\n",
    "    \n",
    "    # Fit and transform for subset_technical\n",
    "    subset_technical[feature + '_Encoded'] = le_technical.fit_transform(subset_technical[feature])\n",
    "    \n",
    "    # Store the mapping for subset_technical\n",
    "    encodings_technical[feature] = dict(zip(le_technical.classes_, le_technical.transform(le_technical.classes_)))\n",
    "    \n",
    "    # If feature exists in subset_original2, apply encoding\n",
    "    if feature in subset_original2:\n",
    "        le_original2 = LabelEncoder()\n",
    "        subset_original2[feature + '_Encoded'] = le_original2.fit_transform(subset_original2[feature])\n",
    "        \n",
    "        # Store the mapping for subset_original2\n",
    "        encodings_original2[feature] = dict(zip(le_original2.classes_, le_original2.transform(le_original2.classes_)))\n",
    "\n",
    "features_original2 = subset_original2[['Gender_Encoded', 'SeniorCitizen_Encoded', 'Marital_Status_Encoded', 'Dependents_Encoded', 'Attrition_Flag_Encoded']]\n",
    "features_technical = subset_technical[['Gender_Encoded', 'SeniorCitizen_Encoded', 'Marital_Status_Encoded', 'Dependents_Encoded', 'Attrition_Flag_Encoded']]\n",
    "# Display the encoding mappings\n",
    "print(\"Encodings for subset_technical:\")\n",
    "for feature, mapping in encodings_technical.items():\n",
    "    print(f\"{feature}: {mapping}\")\n",
    "\n",
    "print(\"\\nEncodings for subset_original2:\")\n",
    "for feature, mapping in encodings_original2.items():\n",
    "    print(f\"{feature}: {mapping}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KMeans clustering on balance data and find optimal clusters\n",
    "cluster_range2 = range(2, 10)  # Define the range of cluster numbers to test\n",
    "inertia_values2 = []  # Inertia will help determine the optimal cluster number\n",
    "\n",
    "for k in cluster_range2:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(features_technical)\n",
    "    inertia_values2.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(cluster_range2, inertia_values2, marker='o', linestyle='--', color='b')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters for Technical Features')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the final KMeans model with the selected number of clusters\n",
    "optimal_k_technical = 5  # Choosen based on the elbow plot\n",
    "kmeans_technical = KMeans(n_clusters=optimal_k, random_state=3101)\n",
    "kmeans_technical.fit(features_technical)\n",
    "subset_technical['Cluster_Labels'] = kmeans_technical.labels_\n",
    "\n",
    "#Predict cluster labels for the original subset using the same KMeans model\n",
    "subset_original2['Cluster_Labels'] = kmeans_technical.predict(features_original2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distribution of PhoneService\n",
    "phone_service_distribution = (\n",
    "    subset_technical.groupby('Cluster_Labels')['PhoneService_Encoded']\n",
    "    .value_counts(normalize=True)\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Calculate the distribution of InternetService\n",
    "internet_service_distribution = (\n",
    "    subset_technical.groupby('Cluster_Labels')['InternetService_Encoded']\n",
    "    .value_counts(normalize=True)\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Calculate the distribution of TechSupport\n",
    "tech_support_distribution = (\n",
    "    subset_technical.groupby('Cluster_Labels')['TechSupport_Encoded']\n",
    "    .value_counts(normalize=True)\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Calculate the distribution of PaperlessBilling\n",
    "paperless_billing_distribution = (\n",
    "    subset_technical.groupby('Cluster_Labels')['PaperlessBilling_Encoded']\n",
    "    .value_counts(normalize=True)\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Calculate the distribution of PaymentMethod\n",
    "payment_method_distribution = (\n",
    "    subset_technical.groupby('Cluster_Labels')['PaymentMethod_Encoded']\n",
    "    .value_counts(normalize=True)\n",
    "    .unstack(fill_value=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_features(df, distribution):\n",
    "    synthetic_feature = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        cluster = row['Cluster_Labels']\n",
    "        \n",
    "        # Sample a new feature based on the defined probabilities\n",
    "        sample = np.random.choice(\n",
    "            distribution.columns,  # Possible features to sample from\n",
    "            p=distribution.loc[cluster].values  # Probabilities for the respective features\n",
    "        )\n",
    "        synthetic_feature.append(sample)\n",
    "            \n",
    "    return synthetic_feature\n",
    "\n",
    "# Generate synthetic features\n",
    "subset_original2['PhoneService'] = generate_synthetic_features(subset_original2, phone_service_distribution)\n",
    "subset_original2['InternetService'] = generate_synthetic_features(subset_original2, internet_service_distribution)\n",
    "subset_original2['TechSupport'] = generate_synthetic_features(subset_original2, tech_support_distribution)\n",
    "subset_original2['PaperlessBilling'] = generate_synthetic_features(subset_original2, paperless_billing_distribution)\n",
    "subset_original2['PaymentMethod'] = generate_synthetic_features(subset_original2, payment_method_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final synthetic dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the final segmentation data for actual segmentation\n",
    "\n",
    "# Feature from original dataset\n",
    "feature_from_original = ['CLIENTNUM','Income_Category','No_of_product',\n",
    "                         'Total_Trans_Amt', 'Total_Trans_Count']\n",
    "temp1 = original.loc[:,feature_from_original]\n",
    "\n",
    "# Feature from balance\n",
    "final_balance_features = ['CLIENTNUM','Credit Score',\n",
    "       'Outstanding Loans', 'Balance']\n",
    "temp2 = subset_original.loc[:,final_balance_features]\n",
    "\n",
    "# Feature from technical\n",
    "final_tech_features = ['CLIENTNUM','PhoneService','InternetService','TechSupport','PaperlessBilling','PaymentMethod']\n",
    "temp3  = subset_original2.loc[:,final_tech_features]\n",
    "\n",
    "\n",
    "# Joingning them all together\n",
    "temp4 = pd.merge(temp1, temp2, on='CLIENTNUM', how='inner')\n",
    "final_df = pd.merge(temp4, temp3, on='CLIENTNUM', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Customer Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Feature Engineering Rules\n",
    "\n",
    "### 3.1.1 Digital Capability\n",
    "We will combine the following features to create the `Digital_Capability` score:\n",
    "- **PhoneService**: \n",
    "  - If the customer has phone service (`PhoneService = 1`), add 1 point. \n",
    "  - Else, do not award any point.\n",
    "- **InternetService**: \n",
    "  - If the customer has **Fiber optic internet**(`InternetService = 1`) or **DSL** (`InternetService = 0`), add 1 points.\n",
    "  - If **NO** (`InternetService = 2`), do not award any point.\n",
    "- **TechSupport**: \n",
    "  - If the customer uses tech support (`TechSupport = 2`), add 1 points.\n",
    "  - If no tech support (`TechSupport = 0` or `TechSupport = 1`), add 0 points.\n",
    "- **PaperlessBilling**: \n",
    "  - If the customer has paperless billing (`PaperlessBilling = 1`), add 1 point\n",
    "  - Else, do not add any point.\n",
    "- **PaymentMethod**: \n",
    "  - If the customer uses **automatic payments** (`PaymentMethod = 0 or 1`), add 2 points.\n",
    "  - If **electronic check** (`PaymentMethod = 2`), add 1 point.\n",
    "  - If **mailed check** (`PaymentMethod = 3`), do not add any point.\n",
    "\n",
    "**Total score range**: 0 to 6  \n",
    "- **Digital Capability**: If digital capability score > 2, return True (indicating digitally capable). Otherwise, return False.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1.3 Financial Status\n",
    "\n",
    "We will combine the following features to create the `Financial_Status` score using **percentiles**, except for **Income_Category**, which will use strict rules:\n",
    "\n",
    "- **Income_Category** (strict rule):\n",
    "  - Assign points based on income category:\n",
    "    - If the income is `120+`, add **3 points**.\n",
    "    - If the income is between `80 - 120`, add **2 points**.\n",
    "    - If the income is between `60 - 80`, add **1 point**.\n",
    "    - If income is `Less than 40`, add **0 points**.\n",
    "\n",
    "- **Credit Score**:\n",
    "  - Assign points based on the credit score percentile:\n",
    "    - If the credit score is in the top 20th percentile, add **3 points**.\n",
    "    - If the credit score is between the 20th and 50th percentile, add **2 points**.\n",
    "    - If the credit score is between the 50th and 80th percentile, add **1 point**.\n",
    "    - If below the 80th percentile, add **0 points**.\n",
    "\n",
    "- **Outstanding Loans**:\n",
    "  - Assign points based on the loan amount percentile:\n",
    "    - If the loan amount is in the bottom 20th percentile (e.g., less than $10,000), add **3 points**.\n",
    "    - If the loan amount is between the 20th and 50th percentile, add **2 points**.\n",
    "    - If the loan amount is between the 50th and 80th percentile, add **1 point**.\n",
    "    - If above the 80th percentile, add **0 points**.\n",
    "\n",
    "- **Balance**:\n",
    "  - Assign points based on the balance percentile:\n",
    "    - If the balance is in the top 20th percentile, add **3 points**.\n",
    "    - If the balance is between the 20th and 50th percentile, add **2 points**.\n",
    "    - If the balance is between the 50th and 80th percentile, add **1 point**.\n",
    "    - If below the 80th percentile, add **0 points**.\n",
    "\n",
    "**Total score range**: 0 to 12 (higher means stronger financial status).\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1.3 Transaction Behavior\n",
    "We will create a composite score for `Transaction_Behavior`:\n",
    "- **Total_Trans_Amt**: \n",
    "  - If the total transaction amount is in the top 20%, add **3 points**.\n",
    "  - If the total transaction amount is in the 20th and 50th percentile, add **2 points**.\n",
    "  - If the total transaction amount is in the 50th and 80th percentile, add **1 point**.\n",
    "- **Total_Trans_Count**: \n",
    "  - If the total transaction count is in the top 20%, add **3 points**.\n",
    "  - If the total transaction count is in the 20th and 50th percentile, add **2 points**.\n",
    "  - If the total transaction count is in the 50th and 80th percentile, add **1 point**.\n",
    "\n",
    "**Total score range**: 0 to 6 (higher means frequent and high-value transactions).\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1.4 Product Usage\n",
    "We will categorize customers based on the number of products they use and assign them a `Product_Usage` label:\n",
    "- **Heavy User**: Customers using more than 4 products, **award 3 points**\n",
    "- **Moderate User**: Customers using 3-4 products, **award 2 points**\n",
    "- **Light User**: Customers using 1-2 or fewer products, **award 1 point**\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1.5 Loyalty Score\n",
    "The `Loyalty` score will be a combination of the **Transaction Behavior** and **Product Usage** scores.\n",
    "\n",
    "**Total Loyalty score range**: 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Integration: Banking Behavior and Customer Preferences\n",
    "\n",
    "#### 1. **Loyalty**\n",
    "Combines `Transaction_Behavious` and `Product_Usage` to measure how engaged the customer is with the bank.\n",
    "Value ranges from 0-9\n",
    "#### 2. **Financial Status**\n",
    "Measures the customer’s financial health based on `income`, `credit score`, `outstanding loans`, and `balance`.\n",
    "Value ranges from 0-12\n",
    "#### 3. **Digital capability**\n",
    "Captures if the customer is good at techonologies.\n",
    "  Score based on `PhoneService`, `InternetService`, `TechSupport`, `PaperlessBilling`, and `PaymentMethod`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-Based Segmentation Based on Banking Behavior and Customer Preferences\n",
    "\n",
    "#### Classification Ranges Based on Percentiles:\n",
    "\n",
    "##### 1. **Loyalty**:\n",
    "We will categorize customers into **Low**, **Moderate**, and **High** loyalty based on the composite `Loyalty_Score`:\n",
    "- **Low (L)**: Loyalty score in the **bottom 20%** of the population.\n",
    "- **Moderate (M)**: Loyalty score between the **20th and 80th percentile**.\n",
    "- **High (H)**: Loyalty score in the **top 20%** of the population.\n",
    "\n",
    "##### 2. **Financial Status**:\n",
    "We will categorize customers into **Low**, **Moderate**, and **High** financial status based on the `Financial_Status` score:\n",
    "- **Low (L)**: Financial status score in the **bottom 20%** of the population.\n",
    "- **Moderate (M)**: Financial status score between the **20th and 80th percentile**.\n",
    "- **High (H)**: Financial status score in the **top 20%** of the population.\n",
    "\n",
    "#### Segments:\n",
    "\n",
    "1. **Low Financial status, Low Loyalty**:\n",
    "   - **Financial status**: Low \n",
    "   - **Loyalty**: Low \n",
    "   - **Business Insight**: Customers in this segment likely include students or younger individuals just starting out, or elderly customers who aren't financially active. A focus on retention strategies and promoting entry-level products (like low-cost savings accounts) is key. Physical outreach methods may be necessary, especially if they lack digital capability.\n",
    "\n",
    "2. **High Financial status, High Loyalty**:\n",
    "   - **Financial status**: High \n",
    "   - **Loyalty**: High \n",
    "   - **Business Insight**: These are premium customers, likely professionals or established individuals with a strong engagement in banking products. Offering personalized premium services, loyalty rewards, and investment products should be prioritized. Reach out via digital channels for convenience, or through dedicated relationship managers.\n",
    "\n",
    "3. **High Financial status, Low or Moderate Loyalty**:\n",
    "   - **Financial status**: High\n",
    "   - **Loyalty**: Low or Moderate\n",
    "   - **Business Insight**: These financially capable customers may not be fully engaged with the bank’s products. They could be busy professionals or high-income earners who focus on other banks. Increase engagement by promoting exclusive offers, premium credit cards, or mortgage products. Encourage digital engagement to make banking easier and more convenient for them.\n",
    "\n",
    "4. **Low or Moderate Financial status, High Loyalty**:\n",
    "   - **Financial status**: Low or Moderate\n",
    "   - **Loyalty**: High\n",
    "   - **Business Insight**: These customers, while financially modest, are loyal users of the bank’s products. Likely individuals in middle-income brackets or those rebuilding credit, they should be offered value-driven products such as cashback credit cards or debt consolidation services. Educating them on budgeting tools via digital channels may improve their financial health.\n",
    "\n",
    "5. **Moderate Financial status, Moderate Loyalty** + **Low Financial status, Moderate Loyalty**, **Moderate Financial status, Low Loyalty**:\n",
    "   - **Financial status**: Moderate or Low\n",
    "   - **Loyalty**: Moderate or Low\n",
    "   - **Business Insight**: This segment represents customers with no strong financial activity or engagement. They could be occasional users, young professionals, or middle-income families. Focus on financial education, product bundling, or targeted campaigns that address their potential needs, such as home loans or long-term savings plans. If digitally capable, promote app-based interactions; otherwise, rely on physical channels.\n",
    "  \n",
    "---\n",
    "\n",
    "**Digital Capability**:\n",
    "- Customers who are digitally capable should be prioritized for online banking services, mobile app usage, and digital communication.\n",
    "- Non-digitally capable customers may prefer physical channels, like branch visits or mailed offers, so consider traditional methods of outreach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerSegmentation:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.percentiles = {}\n",
    "\n",
    "    def calculate_initial_percentiles(self):\n",
    "        # Calculate percentiles for features before Loyalty and Financial_Status are created\n",
    "        self.percentiles['Credit_Score'] = self.df['Credit Score'].quantile([0.2, 0.5, 0.8])\n",
    "        self.percentiles['Outstanding_Loans'] = self.df['Outstanding Loans'].quantile([0.2, 0.5, 0.8])\n",
    "        self.percentiles['Balance'] = self.df['Balance'].quantile([0.2, 0.5, 0.8])\n",
    "        self.percentiles['Total_Trans_Amt'] = self.df['Total_Trans_Amt'].quantile([0.2, 0.5, 0.8])\n",
    "        self.percentiles['Total_Trans_Count'] = self.df['Total_Trans_Count'].quantile([0.2, 0.5, 0.8])\n",
    "\n",
    "    def calculate_final_percentiles(self):\n",
    "        # After Loyalty and Financial_Status have been created, calculate their percentiles\n",
    "        self.percentiles['Loyalty'] = self.df['Loyalty'].quantile([0.2, 0.8])\n",
    "        self.percentiles['Financial_Status'] = self.df['Financial_Status'].quantile([0.2, 0.8])\n",
    "\n",
    "    def digital_capability(self, row):\n",
    "        score = 0\n",
    "        score += row['PhoneService']\n",
    "        score += 1 if row['InternetService'] in [0, 1] else 0\n",
    "        score += 1 if row['TechSupport'] == 2 else 0\n",
    "        score += row['PaperlessBilling']\n",
    "        score += 2 if row['PaymentMethod'] in [0, 1] else 1 if row['PaymentMethod'] == 2 else 0\n",
    "        return score > 2\n",
    "\n",
    "    def financial_status(self, row):\n",
    "        score = 0\n",
    "        # Income Category (strict rules)\n",
    "        if row['Income_Category'] == '120 +':\n",
    "            score += 3\n",
    "        elif row['Income_Category'] == '80 - 120':\n",
    "            score += 2\n",
    "        elif row['Income_Category'] == '60 - 80':\n",
    "            score += 1\n",
    "\n",
    "        # Credit Score (percentile-based)\n",
    "        if row['Credit Score'] > self.percentiles['Credit_Score'][0.8]:\n",
    "            score += 3\n",
    "        elif row['Credit Score'] > self.percentiles['Credit_Score'][0.5]:\n",
    "            score += 2\n",
    "        elif row['Credit Score'] > self.percentiles['Credit_Score'][0.2]:\n",
    "            score += 1\n",
    "\n",
    "        # Outstanding Loans (percentile-based)\n",
    "        if row['Outstanding Loans'] < self.percentiles['Outstanding_Loans'][0.2]:\n",
    "            score += 3\n",
    "        elif row['Outstanding Loans'] < self.percentiles['Outstanding_Loans'][0.5]:\n",
    "            score += 2\n",
    "        elif row['Outstanding Loans'] < self.percentiles['Outstanding_Loans'][0.8]:\n",
    "            score += 1\n",
    "\n",
    "        # Balance (percentile-based)\n",
    "        if row['Balance'] > self.percentiles['Balance'][0.8]:\n",
    "            score += 3\n",
    "        elif row['Balance'] > self.percentiles['Balance'][0.5]:\n",
    "            score += 2\n",
    "        elif row['Balance'] > self.percentiles['Balance'][0.2]:\n",
    "            score += 1\n",
    "\n",
    "        return score\n",
    "\n",
    "    def transaction_behavior(self, row):\n",
    "        score = 0\n",
    "        if row['Total_Trans_Amt'] > self.percentiles['Total_Trans_Amt'][0.8]:\n",
    "            score += 3\n",
    "        elif row['Total_Trans_Amt'] > self.percentiles['Total_Trans_Amt'][0.5]:\n",
    "            score += 2\n",
    "        elif row['Total_Trans_Amt'] > self.percentiles['Total_Trans_Amt'][0.2]:\n",
    "            score += 1\n",
    "\n",
    "        if row['Total_Trans_Count'] > self.percentiles['Total_Trans_Count'][0.8]:\n",
    "            score += 3\n",
    "        elif row['Total_Trans_Count'] > self.percentiles['Total_Trans_Count'][0.5]:\n",
    "            score += 2\n",
    "        elif row['Total_Trans_Count'] > self.percentiles['Total_Trans_Count'][0.2]:\n",
    "            score += 1\n",
    "\n",
    "        return score\n",
    "\n",
    "    def product_usage(self, row):\n",
    "        if row['No_of_product'] > 4:\n",
    "            return 3\n",
    "        elif 3 <= row['No_of_product'] <= 4:\n",
    "            return 2\n",
    "        return 1\n",
    "\n",
    "    def loyalty_score(self, row):\n",
    "        return self.transaction_behavior(row) + self.product_usage(row)\n",
    "\n",
    "    def assign_loyalty_level(self, loyalty_score):\n",
    "        if loyalty_score > self.percentiles['Loyalty'][0.8]:\n",
    "            return 'High'\n",
    "        elif loyalty_score > self.percentiles['Loyalty'][0.2]:\n",
    "            return 'Moderate'\n",
    "        else:\n",
    "            return 'Low'\n",
    "\n",
    "    def assign_financial_status_level(self, financial_status_score):\n",
    "        if financial_status_score > self.percentiles['Financial_Status'][0.8]:\n",
    "            return 'High'\n",
    "        elif financial_status_score > self.percentiles['Financial_Status'][0.2]:\n",
    "            return 'Moderate'\n",
    "        else:\n",
    "            return 'Low'\n",
    "\n",
    "    def assign_segment(self, row):\n",
    "        # Assign loyalty and financial status levels\n",
    "        loyalty_label = self.assign_loyalty_level(row['Loyalty'])\n",
    "        financial_status_label = self.assign_financial_status_level(row['Financial_Status'])\n",
    "\n",
    "        # Return segment based on the classification of loyalty and financial status\n",
    "        if financial_status_label == 'Low' and loyalty_label == 'Low':\n",
    "            return 'Low Financial status, Low Loyalty'\n",
    "        elif financial_status_label == 'High' and loyalty_label == 'High':\n",
    "            return 'High Financial status, High Loyalty'\n",
    "        elif financial_status_label == 'High' and loyalty_label in ['Moderate', 'Low']:\n",
    "            return 'High Financial status, Low or Moderate Loyalty'\n",
    "        elif financial_status_label in ['Moderate', 'Low'] and loyalty_label == 'High':\n",
    "            return 'Low or Moderate Financial status, High Loyalty'\n",
    "        else:\n",
    "            return 'Moderate or Low Financial status, Moderate or Low Loyalty'\n",
    "\n",
    "    def perform_segmentation(self):\n",
    "        # Calculate percentiles for features before Loyalty and Financial Status\n",
    "        self.calculate_initial_percentiles()\n",
    "\n",
    "        self.df['Digital_Capability'] = self.df.apply(self.digital_capability, axis=1)\n",
    "        self.df['Financial_Status'] = self.df.apply(self.financial_status, axis=1)\n",
    "        self.df['Loyalty'] = self.df.apply(self.loyalty_score, axis=1)\n",
    "\n",
    "        # After Loyalty and Financial_Status are created, calculate their percentiles\n",
    "        self.calculate_final_percentiles()\n",
    "\n",
    "        # Assign segment based on loyalty and financial status\n",
    "        self.df['Segment'] = self.df.apply(self.assign_segment, axis=1)\n",
    "\n",
    "        return self.df[['Segment', 'Digital_Capability']]\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        # Apply segmentation logic to new data\n",
    "        new_data['Digital_Capability'] = new_data.apply(self.digital_capability, axis=1)\n",
    "        new_data['Financial_Status'] = new_data.apply(self.financial_status, axis=1)\n",
    "        new_data['Loyalty'] = new_data.apply(self.loyalty_score, axis=1)\n",
    "\n",
    "        # Calculate percentiles for Loyalty and Financial Status based on new data\n",
    "        self.calculate_final_percentiles()\n",
    "\n",
    "        new_data['Segment'] = new_data.apply(self.assign_segment, axis=1)\n",
    "        return new_data[['Segment', 'Digital_Capability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and test with final_df\n",
    "segmentation_test = CustomerSegmentation(final_df)\n",
    "segmentation_result = segmentation_test.perform_segmentation()\n",
    "\n",
    "# Output first few rows and value counts for segmentation\n",
    "print(segmentation_result.head())\n",
    "print(segmentation_result['Segment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of Dynamic model\n",
    "\n",
    "Consider the following scenarios, existing customer may be re-evaluated which cause their credit-score to change over time. Their saving, outstanding loan and income will not likely to be static too. Therefore, the existing data will likely to have changes. In addtion, there will be new customer joining the bank and some old customer terminating their account. Hence, we will need a dynamic model to take such changes into consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "To better illustrate the changes across time, we will add in a new fewture `Time` to keep track of when the data has been updated. We assume that the re-evaluation happens **every week Friday**. For simplicity sake, we will set the first batch of data to be **05/01/2024** which is the first Friday of 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime(\"2024-01-01\")  # Starting date, First friday of 2024\n",
    "final_df.insert(1, 'Time', start_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataManager Class for Customer Data Management\n",
    "\n",
    "### Overview\n",
    "The `DataManager` class is designed to handle the management of customer data within a banking context. It allows for the addition of new customer data, updating existing records, and the removal of churned customers. This class is essential for maintaining an up-to-date customer database that reflects current information accurately.\n",
    "\n",
    "### Features\n",
    "- **Updating Records**: If a customer already exists in the current dataset (identified by `CLIENTNUM`), the class will replace the old record with the new data provided.\n",
    "- **Appending New Records**: If a customer does not exist in the current dataset, the class will append the new record to the dataset.\n",
    "- **Handling Churn**: The class can process a new column called `Churned`. If this value is `1`, indicating the customer has churned, the corresponding record will be removed from the current dataset.\n",
    "- **Getter Function**: A method to retrieve the current state of the dataset after any updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def add_data(self, new_data):\n",
    "        # Set current date (Friday) for new entries\n",
    "        current_time = pd.to_datetime('now').normalize()  # Set current time to the day, ignoring seconds\n",
    "        new_data['Time'] = current_time  # Apply current date\n",
    "\n",
    "        # Set CLIENTNUM as index for easy merging\n",
    "        new_data.set_index('CLIENTNUM', inplace=True)\n",
    "\n",
    "        # Remove churned customers from the current DataFrame\n",
    "        churned_customers = new_data[new_data['Churned'] == 1].index\n",
    "        self.df = self.df[~self.df['CLIENTNUM'].isin(churned_customers)]  # Remove churned customers\n",
    "\n",
    "        # Set CLIENTNUM as index for the current dataframe\n",
    "        self.df.set_index('CLIENTNUM', inplace=True)\n",
    "        \n",
    "        # Update existing records, ignoring churned customers\n",
    "        self.df.update(new_data[new_data['Churned'] == 0])  \n",
    "        \n",
    "        # Append new records that don't exist in the current dataframe\n",
    "        self.df = self.df.combine_first(new_data[new_data['Churned'] == 0])  \n",
    "\n",
    "        # Reset index to return CLIENTNUM as a column\n",
    "        self.df.reset_index(inplace=True)\n",
    "\n",
    "        # Reorder columns to ensure 'Time' is right after 'CLIENTNUM'\n",
    "        cols = list(self.df.columns)\n",
    "        cols.insert(1, cols.pop(cols.index('Time')))  # Move 'Time' to right after 'CLIENTNUM'\n",
    "        self.df = self.df[cols]\n",
    "\n",
    "    def get(self):\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PercentileCalculator:\n",
    "    def __init__(self, df):\n",
    "        # Initialize with existing data\n",
    "        self.df = df.copy()\n",
    "        self.percentiles = {}\n",
    "\n",
    "    def calculate_percentiles(self):\n",
    "        # Calculate percentiles for the required columns\n",
    "        self.percentiles['Credit_Score'] = self.df['Credit Score'].quantile([0.2, 0.5, 0.8])\n",
    "        self.percentiles['Outstanding_Loans'] = self.df['Outstanding Loans'].quantile([0.2, 0.5, 0.8])\n",
    "        self.percentiles['Balance'] = self.df['Balance'].quantile([0.2, 0.5, 0.8])\n",
    "        self.percentiles['Total_Trans_Amt'] = self.df['Total_Trans_Amt'].quantile([0.2, 0.5, 0.8])\n",
    "        self.percentiles['Total_Trans_Count'] = self.df['Total_Trans_Count'].quantile([0.2, 0.5, 0.8])\n",
    "\n",
    "    def calculate_digital_capability(self, row):\n",
    "        score = 0\n",
    "        score += row['PhoneService']\n",
    "        score += 1 if row['InternetService'] in [0, 1] else 0\n",
    "        score += 1 if row['TechSupport'] == 2 else 0\n",
    "        score += row['PaperlessBilling']\n",
    "        score += 2 if row['PaymentMethod'] in [0, 1] else 1 if row['PaymentMethod'] == 2 else 0\n",
    "        return True if score > 2 else False  # Return True for digitally capable, False for not capable\n",
    "\n",
    "    def calculate_financial_status(self, row):\n",
    "        score = 0\n",
    "        # Income Category (strict rules)\n",
    "        if row['Income_Category'] == '120 +':\n",
    "            score += 3\n",
    "        elif row['Income_Category'] == '80 - 120':\n",
    "            score += 2\n",
    "        elif row['Income_Category'] == '60 - 80':\n",
    "            score += 1\n",
    "\n",
    "        # Credit Score (percentile-based)\n",
    "        if row['Credit Score'] > self.percentiles['Credit_Score'][0.8]:\n",
    "            score += 3\n",
    "        elif row['Credit Score'] > self.percentiles['Credit_Score'][0.5]:\n",
    "            score += 2\n",
    "        elif row['Credit Score'] > self.percentiles['Credit_Score'][0.2]:\n",
    "            score += 1\n",
    "\n",
    "        # Outstanding Loans (percentile-based)\n",
    "        if row['Outstanding Loans'] < self.percentiles['Outstanding_Loans'][0.2]:\n",
    "            score += 3\n",
    "        elif row['Outstanding Loans'] < self.percentiles['Outstanding_Loans'][0.5]:\n",
    "            score += 2\n",
    "        elif row['Outstanding Loans'] < self.percentiles['Outstanding_Loans'][0.8]:\n",
    "            score += 1\n",
    "\n",
    "        # Balance (percentile-based)\n",
    "        if row['Balance'] > self.percentiles['Balance'][0.8]:\n",
    "            score += 3\n",
    "        elif row['Balance'] > self.percentiles['Balance'][0.5]:\n",
    "            score += 2\n",
    "        elif row['Balance'] > self.percentiles['Balance'][0.2]:\n",
    "            score += 1\n",
    "\n",
    "        return score\n",
    "\n",
    "    def calculate_loyalty_score(self, row):\n",
    "        # Loyalty is a composite score based on:\n",
    "        # - Total_Trans_Amt: Scaled to a maximum of 3 points.\n",
    "        # - Total_Trans_Count: Scaled to a maximum of 3 points.\n",
    "        # - No_of_product: Heavy User (>4 products): 3 points, Moderate User (3-4 products): 2 points, Light User (<=2 products): 1 point\n",
    "\n",
    "        trans_amt_score = 3 if row['Total_Trans_Amt'] > self.percentiles['Total_Trans_Amt'][0.8] else \\\n",
    "                          2 if row['Total_Trans_Amt'] > self.percentiles['Total_Trans_Amt'][0.5] else \\\n",
    "                          1 if row['Total_Trans_Amt'] > self.percentiles['Total_Trans_Amt'][0.2] else 0\n",
    "\n",
    "        trans_count_score = 3 if row['Total_Trans_Count'] > self.percentiles['Total_Trans_Count'][0.8] else \\\n",
    "                            2 if row['Total_Trans_Count'] > self.percentiles['Total_Trans_Count'][0.5] else \\\n",
    "                            1 if row['Total_Trans_Count'] > self.percentiles['Total_Trans_Count'][0.2] else 0\n",
    "\n",
    "        product_usage_score = 3 if row['No_of_product'] > 4 else 2 if 3 <= row['No_of_product'] <= 4 else 1\n",
    "\n",
    "        return trans_amt_score + trans_count_score + product_usage_score\n",
    "\n",
    "    def perform_feature_engineering(self):\n",
    "        # Perform feature engineering to calculate Financial_Status, Loyalty, and Digital_Capability\n",
    "        self.df['Financial_Status'] = self.df.apply(self.calculate_financial_status, axis=1)\n",
    "        self.df['Loyalty'] = self.df.apply(self.calculate_loyalty_score, axis=1)\n",
    "        self.df['Digital_Capability'] = self.df.apply(self.calculate_digital_capability, axis=1)\n",
    "\n",
    "    def categorize_financial_status_and_loyalty(self):\n",
    "        # Calculate percentiles for Financial_Status and Loyalty\n",
    "        loyalty_percentiles = self.df['Loyalty'].quantile([0.2, 0.8])\n",
    "        financial_status_percentiles = self.df['Financial_Status'].quantile([0.2, 0.8])\n",
    "\n",
    "        # Categorize Financial_Status\n",
    "        self.df['Financial_Status_Category'] = self.df['Financial_Status'].apply(\n",
    "            lambda x: 'Low' if x <= financial_status_percentiles[0.2] else\n",
    "            ('High' if x > financial_status_percentiles[0.8] else 'Moderate'))\n",
    "\n",
    "        # Categorize Loyalty\n",
    "        self.df['Loyalty_Category'] = self.df['Loyalty'].apply(\n",
    "            lambda x: 'Low' if x <= loyalty_percentiles[0.2] else\n",
    "            ('High' if x > loyalty_percentiles[0.8] else 'Moderate'))\n",
    "\n",
    "    def get_featured_data(self):\n",
    "        # Perform feature engineering and return a DataFrame with CLIENTNUM, Time, Financial_Status, Loyalty, and Digital_Capability\n",
    "        self.perform_feature_engineering()\n",
    "        self.categorize_financial_status_and_loyalty()\n",
    "        return self.df[['CLIENTNUM','Time','Financial_Status_Category', 'Loyalty_Category', 'Digital_Capability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmentation:\n",
    "    def __init__(self, original_df, featured_df):\n",
    "        \"\"\"\n",
    "        Initialize the Segmentation class with the original and featured data.\n",
    "        \n",
    "        :param original_df: The original DataFrame from the DataManager.\n",
    "        :param featured_df: The DataFrame output from the PercentileCalculator.\n",
    "        \"\"\"\n",
    "        self.original_df = original_df.copy()\n",
    "        self.featured_df = featured_df.copy()\n",
    "\n",
    "    def apply_segmentation_rule(self, row):\n",
    "        \"\"\"\n",
    "        Apply segmentation rule based on the Financial_Status_Category and Loyalty_Category.\n",
    "        \n",
    "        :param row: A row from the featured_df DataFrame\n",
    "        :return: Segment as per the predefined rules\n",
    "        \"\"\"\n",
    "        financial_status = row['Financial_Status_Category']\n",
    "        loyalty = row['Loyalty_Category']\n",
    "\n",
    "        if financial_status == 'Low' and loyalty == 'Low':\n",
    "            return 'Low Financial status, Low Loyalty'\n",
    "        elif financial_status == 'High' and loyalty == 'High':\n",
    "            return 'High Financial status, High Loyalty'\n",
    "        elif financial_status == 'High' and loyalty in ['Moderate', 'Low']:\n",
    "            return 'High Financial status, Low or Moderate Loyalty'\n",
    "        elif financial_status in ['Moderate', 'Low'] and loyalty == 'High':\n",
    "            return 'Low or Moderate Financial status, High Loyalty'\n",
    "        else:\n",
    "            return 'Moderate or Low Financial status, Moderate or Low Loyalty'\n",
    "\n",
    "    def perform_segmentation(self):\n",
    "        \"\"\"\n",
    "        Perform segmentation and append the SEGMENT column.\n",
    "        \"\"\"\n",
    "        # Apply segmentation rule\n",
    "        self.featured_df['SEGMENT'] = self.featured_df.apply(self.apply_segmentation_rule, axis=1)\n",
    "        \n",
    "        # Combine SEGMENT and DIGITAL_CAPABILITY from featured_df into the original_df\n",
    "        self.original_df = self.original_df.merge(\n",
    "            self.featured_df[['CLIENTNUM', 'SEGMENT','Digital_Capability']],\n",
    "            on='CLIENTNUM',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    def get_segment_result(self):\n",
    "        \"\"\"\n",
    "        Get the result DataFrame with only CLIENTNUM,Time, SEGMENT, and DIGITAL_Capability (True/False).\n",
    "        \n",
    "        :return: A DataFrame containing CLIENTNUM, SEGMENT, and Digital_Capability.\n",
    "        \"\"\"\n",
    "        return self.original_df[['CLIENTNUM','Time', 'SEGMENT', 'Digital_Capability']]\n",
    "\n",
    "    def get_original_with_segment(self):\n",
    "        \"\"\"\n",
    "        Get the original DataFrame with SEGMENT appended.\n",
    "        \n",
    "        :return: The original DataFrame with SEGMENT columns.\n",
    "        \"\"\"\n",
    "        return self.original_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicCustomerSegmentation:\n",
    "    def __init__(self, initial_data):\n",
    "        \"\"\"\n",
    "        Initialize the dynamic cluster segmentation with the initial dataset.\n",
    "        \n",
    "        :param initial_data: The original dataset, typically the output of DataManager.\n",
    "        \"\"\"\n",
    "        self.data_manager = DataManager(initial_data)\n",
    "\n",
    "    def process_new_data(self, new_data):\n",
    "        \"\"\"\n",
    "        Process new data through the pipeline.\n",
    "        \n",
    "        :param new_data: The new batch of data to be processed.\n",
    "        :return: A DataFrame with CLIENTNUM, SEGMENT, and DIGITAL_CAPABILITY by default.\n",
    "        \"\"\"\n",
    "        # Step 1: Update the dataset using DataManager\n",
    "        self.data_manager.add_data(new_data)\n",
    "        updated_df = self.data_manager.get()\n",
    "\n",
    "        # Step 2: Recalculate percentiles and perform feature engineering using PercentileCalculator\n",
    "        percentile_calculator = PercentileCalculator(updated_df)\n",
    "        percentile_calculator.calculate_percentiles()\n",
    "        featured_data = percentile_calculator.get_featured_data()\n",
    "\n",
    "        # Step 3: Perform segmentation using Segmentation class\n",
    "        segmentation = Segmentation(original_df=updated_df, featured_df=featured_data)\n",
    "        segmentation.perform_segmentation()\n",
    "\n",
    "        # Step 4: Return the segmented result\n",
    "        segmented_result = segmentation.get_segment_result()  # Simplified output with CLIENTNUM, SEGMENT, DIGITAL_CAPABILITY\n",
    "        return segmented_result\n",
    "\n",
    "    def get_full_original_with_segment(self):\n",
    "        \"\"\"\n",
    "        Get the full original DataFrame with SEGMENT and DIGITAL_CAPABILITY appended.\n",
    "        \n",
    "        :return: The original DataFrame with the additional segmentation info.\n",
    "        \"\"\"\n",
    "        segmentation = Segmentation(self.data_manager.get(), self.data_manager.get())  # Dummy instance for the getter\n",
    "        return segmentation.get_original_with_segment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Faker library to generate synthetic data for simulation\n",
    "\n",
    "The following is the synthetic data we will use to simulate the streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Define the function to generate new data\n",
    "def generate_data(existing_df, num_records=1000, churn_rate=0.1):\n",
    "    # Get existing client numbers\n",
    "    existing_clients = existing_df['CLIENTNUM'].values\n",
    "    \n",
    "    # Randomly choose a number between 0% and 80% of total records for updating existing clients\n",
    "    num_existing = int(np.random.uniform(0.0, 0.8) * num_records)\n",
    "    \n",
    "    # Ensure we do not exceed the actual number of existing clients\n",
    "    num_existing = min(num_existing, len(existing_clients))\n",
    "    \n",
    "    # Remaining records are new customers\n",
    "    num_new = num_records - num_existing\n",
    "    \n",
    "    # Select random existing clients for updates\n",
    "    updated_client_nums = np.random.choice(existing_clients, size=num_existing, replace=False)\n",
    "    \n",
    "    # Generate new client numbers for new customers\n",
    "    new_client_nums = np.arange(existing_clients.max() + 1, existing_clients.max() + 1 + num_new)\n",
    "    \n",
    "    # Create updated records for existing clients\n",
    "    updated_data = []\n",
    "    for client in updated_client_nums:\n",
    "        updated_data.append({\n",
    "            'CLIENTNUM': client,\n",
    "            'Income_Category': fake.random_element(elements=('Less than 40', '40 - 60', '60 - 80', '80 - 120', '120 +')),\n",
    "            'No_of_product': fake.random_int(min=1, max=6),\n",
    "            'Total_Trans_Amt': fake.random_int(min=500, max=5000),\n",
    "            'Total_Trans_Count': fake.random_int(min=10, max=100),\n",
    "            'Credit Score': fake.random_int(min=300, max=850),\n",
    "            'Outstanding Loans': fake.random_int(min=0, max=50000),\n",
    "            'Balance': fake.random_int(min=0, max=300000),\n",
    "            'PhoneService': fake.random_int(min=0, max=1),\n",
    "            'InternetService': fake.random_int(min=0, max=2),\n",
    "            'TechSupport': fake.random_int(min=0, max=2),\n",
    "            'PaperlessBilling': fake.random_int(min=0, max=1),\n",
    "            'PaymentMethod': fake.random_int(min=0, max=3),\n",
    "            'Churned': 0  # Initially set as not churned\n",
    "        })\n",
    "    \n",
    "    # Apply churn rate: randomly set a portion of updated clients to churned based on churn_rate\n",
    "    num_churned = int(churn_rate * num_existing)\n",
    "    churned_clients = np.random.choice(range(num_existing), size=num_churned, replace=False)\n",
    "    \n",
    "    for i in churned_clients:\n",
    "        updated_data[i]['Churned'] = 1  # Mark these clients as churned\n",
    "\n",
    "    # Create new customer records (with no churn)\n",
    "    new_data = []\n",
    "    for client in new_client_nums:\n",
    "        new_data.append({\n",
    "            'CLIENTNUM': client,\n",
    "            'Income_Category': fake.random_element(elements=('Less than 40', '40 - 60', '60 - 80', '80 - 120', '120 +')),\n",
    "            'No_of_product': fake.random_int(min=1, max=6),\n",
    "            'Total_Trans_Amt': fake.random_int(min=500, max=5000),\n",
    "            'Total_Trans_Count': fake.random_int(min=10, max=100),\n",
    "            'Credit Score': fake.random_int(min=300, max=850),\n",
    "            'Outstanding Loans': fake.random_int(min=0, max=50000),\n",
    "            'Balance': fake.random_int(min=0, max=300000),\n",
    "            'PhoneService': fake.random_int(min=0, max=1),\n",
    "            'InternetService': fake.random_int(min=0, max=2),\n",
    "            'TechSupport': fake.random_int(min=0, max=2),\n",
    "            'PaperlessBilling': fake.random_int(min=0, max=1),\n",
    "            'PaymentMethod': fake.random_int(min=0, max=3),\n",
    "            'Churned': 0  # New customers are not churned\n",
    "        })\n",
    "    \n",
    "    # Combine updated and new data into one DataFrame\n",
    "    all_data = pd.DataFrame(updated_data + new_data)\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_1 = generate_data(final_df, num_records=8000, churn_rate=0.05) # Smaller set, low churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of dynamic model:\n",
    "# Initialize with the initial dataset (final_df)\n",
    "dynamic_segmentation = DynamicCustomerSegmentation(initial_data=final_df)\n",
    "\n",
    "# Process new data (simulation_1) and get the segmented result\n",
    "segmented_result = dynamic_segmentation.process_new_data(simulation_1)\n",
    "\n",
    "# Optionally, get the full original data with SEGMENT and DIGITAL_CAPABILITY appended\n",
    "full_data_with_segments = dynamic_segmentation.get_full_original_with_segment()\n",
    "\n",
    "# Display the segmented result\n",
    "print(segmented_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer characteristics involved: **product usage**, **transaction history**, **digital engagement**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Visualisation for Product Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Bar Plot for Product Usage across All Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_usage_df = segmentation_test.df.groupby('Segment')['No_of_product'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 5))\n",
    "\n",
    "product_usage_df.plot(kind='bar', ax=ax, colormap='viridis')\n",
    "\n",
    "for i in range(product_usage_df.shape[0]):\n",
    "    for j in range(product_usage_df.shape[1]):\n",
    "        count = product_usage_df.iat[i, j]\n",
    "        if count != 0:\n",
    "            ax.text(i+(j/product_usage_df.shape[1]-0.5)*0.5+0.04, count+5, count,\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend(title = 'Number of Products')\n",
    "plt.title('The Count of Customers Grouped by\\nNumber of Products across Segments', fontsize=20)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Bar Plot for Product Usage across Non-Default Segments\n",
    "\n",
    "The default segment, **Moderate or Low Financial status, Moderate or Low Loyalty**, contains much more customers than the other 4 categories. Hence, we make an additional plot for **the non-default segments only** for a clearer visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_usage_df_nondefault = product_usage_df[product_usage_df.index != 'Moderate or Low Financial status, Moderate or Low Loyalty']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 5))\n",
    "\n",
    "product_usage_df_nondefault.plot(kind='bar', ax=ax, colormap='viridis')\n",
    "\n",
    "for i in range(product_usage_df_nondefault.shape[0]):\n",
    "    for j in range(product_usage_df_nondefault.shape[1]):\n",
    "        count = product_usage_df_nondefault.iat[i, j]\n",
    "        if count != 0:\n",
    "            ax.text(i+(j/product_usage_df_nondefault.shape[1]-0.5)*0.5+0.04, count, count,\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend(title = 'Number of Products')\n",
    "plt.title('The Count of Customers Grouped by\\nNumber of Products across Non-Default Segments', fontsize=20)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Visualisation for Transaction History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Visualisation for Transaction Amount across Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_amount_df = segmentation_test.df.groupby('Segment')['Total_Trans_Amt'].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(35, 10))\n",
    "colours = plt.cm.inferno(np.linspace(0, 1, len(trans_amount_df)))\n",
    "bars = ax.bar(trans_amount_df.index, trans_amount_df.values, color=colours)\n",
    "#trans_amount_df.plot(kind='bar', ax=ax, color=colours)\n",
    "for bar in bars:\n",
    "    ax.text(bar.get_x()+bar.get_width()/2, bar.get_height()+50, int(bar.get_height()),\n",
    "            ha='center', va='bottom', fontsize=20)\n",
    "ax.set_xticklabels([segment.replace(', ', ',\\n') for segment in trans_amount_df.index.tolist()], rotation=0)\n",
    "ax.tick_params(axis='both', labelsize=20)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Average Transaction Amount', fontsize=25)\n",
    "plt.title('The Average Transaction Amount across Segments', fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Visualisation for Transaction Count across Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_count_df = segmentation_test.df.groupby('Segment')['Total_Trans_Count'].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(35, 10))\n",
    "colours = plt.cm.magma(np.linspace(0, 1, len(trans_count_df)))\n",
    "bars = ax.bar(trans_count_df.index, trans_count_df.values, color=colours)\n",
    "#trans_count_df.plot(kind='bar', ax=ax, color=colours)\n",
    "for bar in bars:\n",
    "    ax.text(bar.get_x()+bar.get_width()/2, bar.get_height()+0.5, int(bar.get_height()),\n",
    "            ha='center', va='bottom', fontsize=20)\n",
    "ax.set_xticklabels([segment.replace(', ', ',\\n') for segment in trans_count_df.index.tolist()], rotation=0)\n",
    "ax.tick_params(axis='both', labelsize=20)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Average Transaction Count', fontsize=25)\n",
    "plt.title('The Average Transaction Count across Segments', fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Visualisation for Digital Engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df = segmentation_test.df[['Digital_Capability', 'PhoneService', 'InternetService', \n",
    "                                   'TechSupport', 'PaperlessBilling', 'PaymentMethod']]\n",
    "\n",
    "digital_df['PhoneService'] = \\\n",
    "    digital_df['PhoneService'].replace({0: 'No', \n",
    "                                        1: 'Yes'})\n",
    "digital_df['InternetService'] = \\\n",
    "    digital_df['InternetService'].replace({0: 'DSL', \n",
    "                                           1: 'Fiber Optic',\n",
    "                                           2: 'No Internet Service'})\n",
    "digital_df['TechSupport'] = \\\n",
    "    digital_df['TechSupport'].replace({0: 'No', \n",
    "                                       1: 'No Internet Service',\n",
    "                                       2: 'Yes'})\n",
    "digital_df['PaperlessBilling'] = \\\n",
    "    digital_df['PaperlessBilling'].replace({0: 'No', \n",
    "                                            1: 'Yes'})\n",
    "digital_df['PaymentMethod'] = \\\n",
    "    digital_df['PaymentMethod'].replace({0: 'Bank transfer (automatic)', \n",
    "                                         1: 'Credit card (automatic)',\n",
    "                                         2: 'Electronic check',\n",
    "                                         3: 'Mailed check'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Visualisation for Count of Customers with Different Technical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_features = ['PhoneService', 'InternetService', 'TechSupport', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 10), sharey=True)\n",
    "\n",
    "for i, feature in enumerate(digital_features):\n",
    "    counts = digital_df.groupby('Digital_Capability')[feature].value_counts().unstack(fill_value=0)\n",
    "\n",
    "    curr_height = np.zeros(len(counts))\n",
    "\n",
    "    for category in counts.columns:\n",
    "        axes[i].bar(counts.index, counts[category], bottom=curr_height, label=category)\n",
    "        curr_height += counts[category]\n",
    "\n",
    "        for j, count in enumerate(counts[category]):\n",
    "            if count > 100:\n",
    "                axes[i].text(j, curr_height[j]-count/2, count,\n",
    "                            ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    axes[i].set_ylim(0, 7500)\n",
    "    axes[i].set_title(feature)\n",
    "    axes[i].set_xticks(counts.index)\n",
    "    axes[i].set_xticklabels(['Low', 'High'])\n",
    "    axes[i].legend(title=feature, bbox_to_anchor=(0,1), loc='upper left')\n",
    "\n",
    "axes[0].set_ylabel('Count', fontsize=15)\n",
    "axes[2].set_xlabel('Digital Capability', fontsize=15)\n",
    "plt.suptitle('Count of Customers with Different Technical Features', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Visualisation for Proportion of Customers with Different Technical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_features = ['PhoneService', 'InternetService', 'TechSupport', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 10), sharey=True)\n",
    "\n",
    "for i, feature in enumerate(digital_features):\n",
    "    proportions = digital_df.groupby('Digital_Capability')[feature].value_counts(normalize=True).unstack(fill_value=0)\n",
    "\n",
    "    curr_height = np.zeros(len(proportions))\n",
    "\n",
    "    for category in proportions.columns:\n",
    "        axes[i].bar(proportions.index, proportions[category], bottom=curr_height, label=category)\n",
    "        curr_height += proportions[category]\n",
    "\n",
    "        for j, proportion in enumerate(proportions[category]):\n",
    "            if proportion > 0.05:\n",
    "                axes[i].text(j, curr_height[j]-proportion/2, f'{round(proportion*100, 1)}%', ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    axes[i].set_ylim(0, 1)\n",
    "    axes[i].set_title(feature)\n",
    "    axes[i].set_xticks(proportions.index)\n",
    "    axes[i].set_xticklabels(['Low', 'High'])\n",
    "    axes[i].legend(title=feature, bbox_to_anchor=(0,-0.10), loc='upper left')\n",
    "\n",
    "axes[0].set_ylabel('Percentage', fontsize=15)\n",
    "axes[2].set_xlabel('Digital Capability', fontsize=15)\n",
    "plt.suptitle('Proportion of Customers with Different Technical Features', fontsize=25)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
